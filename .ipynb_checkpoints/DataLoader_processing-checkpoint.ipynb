{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47347e6d",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "### Access all dataset here: \n",
    "https://imperiallondon-my.sharepoint.com/:f:/g/personal/dlc19_ic_ac_uk/EgobSIgJFitCuMdL0Sg6KmABP7qqtibuOz1R1jIZDEX22Q?e=U5CfiK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5c91224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /media/SharedUsers/mj719/home/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# All imports \n",
    "##################\n",
    "\n",
    "#sys libs\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#data manupulation libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from pandarallel import pandarallel\n",
    "\n",
    "# Initialization\n",
    "#pandarallel.initialize()\n",
    "\n",
    "#string manupulation libs\n",
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')\n",
    "\n",
    "#torch libs\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import transformers\n",
    "\n",
    "from transformers import BertTokenizer, AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "# data manipulations\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "import pydicom\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78effb42",
   "metadata": {},
   "source": [
    "### Data Preprocessing - done separately from data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db627f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_temp = pd.read_csv('../../train_raw_reports.csv')\n",
    "df_test_temp = pd.read_csv('../../test_raw_reports.csv')\n",
    "\n",
    "#convetring study id to string as it doesn't work as an int\n",
    "df_train_temp['study_id']=df_train_temp['study_id'].astype(str)\n",
    "df_test_temp['study_id']=df_test_temp['study_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bfed6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>raw_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50414267</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53189527</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53911762</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56699142</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57375967</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id                                         raw_report\n",
       "0  50414267                                   FINAL REPORT\\...\n",
       "1  53189527                                   FINAL REPORT\\...\n",
       "2  53911762                                   FINAL REPORT\\...\n",
       "3  56699142                                   FINAL REPORT\\...\n",
       "4  57375967                                   FINAL REPORT\\..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display raw reports in a dataframe\n",
    "df_train_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7025f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing of the train dataset\n",
    "def preprocessing(text):\n",
    "        cleanedReport = re.sub(r'[^\\w\\s]','',text)            # remove punctuation (not word characters and whitespace)\n",
    "        cleanedReport = re.sub('_', '', cleanedReport)        # remove __ in the report\n",
    "        cleanedReport = re.sub(r'[\\d-]', '', cleanedReport)   # remove numbers in the report \n",
    "        cleanedReport = re.sub('\\n', '', cleanedReport)\n",
    "\n",
    "        return cleanedReport   \n",
    "    \n",
    "\n",
    "def preprocessDataframe(df):\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        preprocessedText = preprocessing(df.at[i, \"raw_report\"])\n",
    "    \n",
    "        df.at[i,'raw_report'] = preprocessedText\n",
    "        i = i + 1 \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e5cf2133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the raw reports in the dataframe \n",
    "df_train_preprocessed = preprocessDataframe(df_train_temp)\n",
    "df_test_preprocessed = preprocessDataframe(df_test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6fc9963c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>raw_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50414267</td>\n",
       "      <td>FINAL REPORT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53189527</td>\n",
       "      <td>FINAL REPORT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53911762</td>\n",
       "      <td>FINAL REPORT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56699142</td>\n",
       "      <td>FINAL REPORT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57375967</td>\n",
       "      <td>FINAL REPORT ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id                                         raw_report\n",
       "0  50414267                                   FINAL REPORT ...\n",
       "1  53189527                                   FINAL REPORT ...\n",
       "2  53911762                                   FINAL REPORT ...\n",
       "3  56699142                                   FINAL REPORT ...\n",
       "4  57375967                                   FINAL REPORT ..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_preprocessed.head() # check if that worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "274ab2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed.to_csv('train_preprocessed.csv', index=False)\n",
    "df_test_preprocessed.to_csv('test_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d844f0",
   "metadata": {},
   "source": [
    "### Data Loader\n",
    "- Include: loading data, text preprocessing, words frequency check, tokenization, tokens-IDs-conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2b0e362a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ef8fdca0954c73b8c5a9fd202f984a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cfeb66e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-999a6f78add30544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /media/SharedUsers/mj719/home/.cache/huggingface/datasets/csv/default-999a6f78add30544/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a6e0e5eaf5429886f0fda06e778d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84796757b21470e8ded920a76538bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /media/SharedUsers/mj719/home/.cache/huggingface/datasets/csv/default-999a6f78add30544/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310dfae40816482ab8b2a2ae6e070952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['study_id', 'raw_report'],\n",
       "        num_rows: 222337\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['study_id', 'raw_report'],\n",
       "        num_rows: 3269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_files = {\"train\": \"train_preprocessed.csv\", \"test\": \"test_preprocessed.csv\"}\n",
    "reports_dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "reports_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0bfeccf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['study_id', 'raw_report'],\n",
       "    num_rows: 222337\n",
       "})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of how to acess one report as a dataset\n",
    "reports_dataset[\"train\"]\n",
    "#example of how to acess only written report \n",
    "#reports_dataset[\"train\"]['raw_report'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4491208b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /media/SharedUsers/mj719/home/.cache/huggingface/datasets/csv/default-999a6f78add30544/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-7e822d87f42e973e.arrow\n",
      "Loading cached processed dataset at /media/SharedUsers/mj719/home/.cache/huggingface/datasets/csv/default-999a6f78add30544/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-98005d92f143e4a9.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68b7e64723b44158d0c06c856db2fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc902d6ce51a456ca563a4f073286ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 206331\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 3345\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(dataset):\n",
    "    result = tokenizer(dataset[\"raw_report\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = reports_dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"raw_report\", \"study_id\"]\n",
    ")\n",
    "\n",
    "\n",
    "chunk_size = 128\n",
    "\n",
    "def group_texts(dataset):\n",
    "    # Concatenate all texts\n",
    "    concatenated_text = {k: sum(dataset[k], []) for k in dataset.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_text[list(dataset.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_text.items()\n",
    "    }\n",
    "    # Create a new labels column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e28cbc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721c447caf0d49ef86c76aa09eddb92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91abfd969ff40ae970b369bdf18c4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split, dataset in lm_datasets.items():\n",
    "    dataset.to_csv(f\"train_dataset_{split}.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "af970dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "64413366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /media/SharedUsers/mj719/home/.cache/huggingface/datasets/csv/default-999a6f78add30544/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-4df61c33141bb878.arrow\n",
      "Loading cached processed dataset at /media/SharedUsers/mj719/home/.cache/huggingface/datasets/csv/default-999a6f78add30544/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-986483f35e2862d4.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function_padding(dataset):\n",
    "    result = tokenizer(dataset[\"raw_report\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets_padded = reports_dataset.map(\n",
    "    tokenize_function_padding, batched=True, remove_columns=[\"raw_report\", \"study_id\"])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31c735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
