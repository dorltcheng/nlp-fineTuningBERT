{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf62a19",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "### Access all dataset here: \n",
    "https://imperiallondon-my.sharepoint.com/:f:/g/personal/dlc19_ic_ac_uk/EgobSIgJFitCuMdL0Sg6KmABP7qqtibuOz1R1jIZDEX22Q?e=U5CfiK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74b8df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /media/SharedUsers/mj719/home/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# All imports \n",
    "##################\n",
    "\n",
    "#sys libs\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#data manupulation libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from pandarallel import pandarallel\n",
    "\n",
    "# Initialization\n",
    "#pandarallel.initialize()\n",
    "\n",
    "#string manupulation libs\n",
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')\n",
    "\n",
    "#torch libs\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import transformers\n",
    "\n",
    "from transformers import BertTokenizer, AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "# data manipulations\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "import pydicom\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc846ad5",
   "metadata": {},
   "source": [
    "### Data Preprocessing - done separately from data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e558188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_temp = pd.read_csv('../../train_raw_reports.csv')\n",
    "df_test_temp = pd.read_csv('../../test_raw_reports.csv')\n",
    "\n",
    "#convetring study id to string as it doesn't work as an int\n",
    "df_train_temp['study_id']=df_train_temp['study_id'].astype(str)\n",
    "df_test_temp['study_id']=df_test_temp['study_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "243256de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>raw_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50414267</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53189527</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53911762</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56699142</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57375967</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id                                         raw_report\n",
       "0  50414267                                   FINAL REPORT\\...\n",
       "1  53189527                                   FINAL REPORT\\...\n",
       "2  53911762                                   FINAL REPORT\\...\n",
       "3  56699142                                   FINAL REPORT\\...\n",
       "4  57375967                                   FINAL REPORT\\..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display raw reports in a dataframe\n",
    "df_train_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69af0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing of the train dataset\n",
    "def preprocessing(text):\n",
    "        cleanedReport = re.sub(r'[^\\w\\s]','',text)            # remove punctuation (not word characters and whitespace)\n",
    "        cleanedReport = re.sub('_', '', cleanedReport)        # remove __ in the report\n",
    "        cleanedReport = re.sub(r'[\\d-]', '', cleanedReport)   # remove numbers in the report \n",
    "        cleanedReport = re.sub('\\n', '', cleanedReport)\n",
    "\n",
    "        return cleanedReport   \n",
    "    \n",
    "\n",
    "def preprocessDataframe(df):\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        preprocessedText = preprocessing(df.at[i, \"raw_report\"])\n",
    "    \n",
    "        df.at[i,'raw_report'] = preprocessedText\n",
    "        i = i + 1 \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a558c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the raw reports in the dataframe \n",
    "df_train_preprocessed = preprocessDataframe(df_train_temp)\n",
    "df_test_preprocessed = preprocessDataframe(df_test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c118771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>raw_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50414267</td>\n",
       "      <td>FINAL REPORT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53189527</td>\n",
       "      <td>FINAL REPORT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53911762</td>\n",
       "      <td>FINAL REPORT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56699142</td>\n",
       "      <td>FINAL REPORT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57375967</td>\n",
       "      <td>FINAL REPORT ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id                                         raw_report\n",
       "0  50414267                                   FINAL REPORT ...\n",
       "1  53189527                                   FINAL REPORT ...\n",
       "2  53911762                                   FINAL REPORT ...\n",
       "3  56699142                                   FINAL REPORT ...\n",
       "4  57375967                                   FINAL REPORT ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_preprocessed.head() # check if that worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78eab058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed.to_csv('train_preprocessed.csv', index=False)\n",
    "df_test_preprocessed.to_csv('test_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc13ae2c",
   "metadata": {},
   "source": [
    "### Data Loader\n",
    "- Include: loading data, text preprocessing, words frequency check, tokenization, tokens-IDs-conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09906585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9763a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3c68b4a32992d3a8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /media/SharedUsers/mj719/home/.cache/huggingface/datasets/csv/default-3c68b4a32992d3a8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fe9a2e7b0a4f7b8267eddc23dbd0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ff43bc303547e182027d693f5caa15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /media/SharedUsers/mj719/home/.cache/huggingface/datasets/csv/default-3c68b4a32992d3a8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771ce8a3ee9544668b2c4e4aa724bab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['study_id', 'raw_report'],\n",
       "        num_rows: 222337\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['study_id', 'raw_report'],\n",
       "        num_rows: 3269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_files = {\"train\": \"train_preprocessed.csv\", \"test\": \"test_preprocessed.csv\"}\n",
    "reports_dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "reports_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea250a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['study_id', 'raw_report'],\n",
       "    num_rows: 222337\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of how to acess one report as a dataset\n",
    "reports_dataset[\"train\"]\n",
    "#example of how to acess only written report \n",
    "#reports_dataset[\"train\"]['raw_report'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1178d80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bb9b00396444d78f4951609f0697d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf7fc82415340409ae459957899067b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06747f4e43f7496c93c156b0ecc92678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b72623698c4b3fa89f743deb10cc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 206331\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 3345\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(dataset):\n",
    "    result = tokenizer(dataset[\"raw_report\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = reports_dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"raw_report\", \"study_id\"]\n",
    ")\n",
    "\n",
    "\n",
    "chunk_size = 128\n",
    "\n",
    "def group_texts(dataset):\n",
    "    # Concatenate all texts\n",
    "    concatenated_text = {k: sum(dataset[k], []) for k in dataset.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_text[list(dataset.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_text.items()\n",
    "    }\n",
    "    # Create a new labels column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d68fea99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbcad6d46ab4d60a59e62e9e9aa630c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352e3a35a11f4067ad5058bedabab265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split, dataset in lm_datasets.items():\n",
    "    dataset.to_csv(f\"final_dataset_chunked{split}.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f463ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033d273c70b84ae4bdc1c913ac8343e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee4b85e4b99446fa730368aa9719465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 222337\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 3269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function_padding(dataset):\n",
    "    result = tokenizer(dataset[\"raw_report\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "        \n",
    "    return result\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = reports_dataset.map(\n",
    "    tokenize_function_padding, batched=True, remove_columns=[\"raw_report\", \"study_id\"])\n",
    "\n",
    "tokenized_datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfe4c896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1509,\n",
       " 2592,\n",
       " 8179,\n",
       " 2229,\n",
       " 185,\n",
       " 1161,\n",
       " 1105,\n",
       " 2495,\n",
       " 1204,\n",
       " 12754,\n",
       " 175,\n",
       " 1114,\n",
       " 1207,\n",
       " 15415,\n",
       " 1112,\n",
       " 14375,\n",
       " 1116,\n",
       " 174,\n",
       " 7501,\n",
       " 1111,\n",
       " 8974,\n",
       " 5531,\n",
       " 2229,\n",
       " 185,\n",
       " 1161,\n",
       " 1105,\n",
       " 11937,\n",
       " 7577,\n",
       " 3839,\n",
       " 9505,\n",
       " 1175,\n",
       " 1110,\n",
       " 1185,\n",
       " 17811,\n",
       " 20994,\n",
       " 185,\n",
       " 1513,\n",
       " 12602,\n",
       " 174,\n",
       " 3101,\n",
       " 17268,\n",
       " 1137,\n",
       " 185,\n",
       " 1673,\n",
       " 1818,\n",
       " 12858,\n",
       " 25632,\n",
       " 20557,\n",
       " 6873,\n",
       " 5552,\n",
       " 11769,\n",
       " 7409,\n",
       " 4233,\n",
       " 1115,\n",
       " 1211,\n",
       " 2620,\n",
       " 4248,\n",
       " 15070,\n",
       " 6719,\n",
       " 1103,\n",
       " 3621,\n",
       " 2660,\n",
       " 16418,\n",
       " 2050,\n",
       " 14196,\n",
       " 27316,\n",
       " 1110,\n",
       " 2999,\n",
       " 16973,\n",
       " 1933,\n",
       " 1166,\n",
       " 1103,\n",
       " 1286,\n",
       " 13093,\n",
       " 9046,\n",
       " 1439,\n",
       " 1103,\n",
       " 7209,\n",
       " 1103,\n",
       " 3077,\n",
       " 1181,\n",
       " 3105,\n",
       " 14701,\n",
       " 1110,\n",
       " 8362,\n",
       " 16996,\n",
       " 23822,\n",
       " 1895,\n",
       " 13306,\n",
       " 19353,\n",
       " 24211,\n",
       " 1785,\n",
       " 1104,\n",
       " 1103,\n",
       " 16530,\n",
       " 1286,\n",
       " 3971,\n",
       " 1105,\n",
       " 5001,\n",
       " 10346,\n",
       " 1132,\n",
       " 2382,\n",
       " 8351,\n",
       " 1185,\n",
       " 12104,\n",
       " 3621,\n",
       " 2660,\n",
       " 16091,\n",
       " 13505,\n",
       " 7637,\n",
       " 1616,\n",
       " 1965,\n",
       " 102]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0f046b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9164201e07684c6f9e4de2ce093561eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760d3b21125749cb9f96b2598e13470a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def padding(dataset):\n",
    "    \n",
    "    #for train dataset\n",
    "\n",
    "    \n",
    "    num_items = len(dataset['input_ids']) # to get number of all items in train dataset\n",
    "        \n",
    "        \n",
    "    if (len(dataset['input_ids'])) > 300:\n",
    "        \n",
    "        while(len(dataset['input_ids']) > 300):\n",
    "            dataset['input_ids'].pop()\n",
    "            dataset['token_type_ids'].pop()\n",
    "            dataset['attention_mask'].pop()\n",
    "            dataset['word_ids'].pop()\n",
    "\n",
    "    while(len(dataset['input_ids']) < 301):\n",
    "\n",
    "        dataset['input_ids'].append(0)\n",
    "        dataset['token_type_ids'].append(0)\n",
    "        dataset['attention_mask'].append(0)\n",
    "        dataset['word_ids'].append(0)\n",
    " \n",
    "\n",
    "    return dataset\n",
    "\n",
    "padded_dataset = tokenized_datasets.map(padding, batched=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "997ede6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_dataset[\"test\"][\"input_ids\"][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4968755a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1d3c1c9d0b4341bfb268a4a7f9f809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f3e78d84924c938099dbf7bd51f4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 222337\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 3269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_function(dataset):\n",
    "\n",
    "    lenReport = len(dataset['input_ids'])\n",
    "    \n",
    "    if (lenReport > 301):\n",
    "        print('yes')\n",
    "    return dataset\n",
    "\n",
    "padded_dataset.map(check_function, batched = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fec8530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe7d84ca8e04d848d2f67de4801da01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/23 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c155375e5fe4e16b173aa8322718889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split, dataset in padded_dataset.items():\n",
    "    dataset.to_csv(f\"final_dataset_padded_{split}.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b6c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
